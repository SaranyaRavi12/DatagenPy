{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lookup Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " import pandas as pd\n",
    " import numpy as np\n",
    " import glob\n",
    " import random\n",
    " import string\n",
    " from faker import Faker\n",
    "\n",
    " faker=Faker()\n",
    "\n",
    " # Function to generate random string of a given length\n",
    " def random_string(length):\n",
    "     return ''.join(random.choices(string.ascii_lowercase, k=length))\n",
    " # Function to generate random integer with a specific number of digits\n",
    " def random_integer(min_digits, max_digits):\n",
    "     min_value = 10**(min_digits - 1)\n",
    "     max_value = 10**max_digits - 1\n",
    "     return np.random.randint(min_value, max_value + 1,dtype=np.int64)\n",
    " # Function to generate data based on schema\n",
    " def generate_data(schema, num_rows):\n",
    "     data = {}\n",
    "     for index, row in schema.iterrows():\n",
    "         col = row[0]\n",
    "         dtype_info = row[1]\n",
    "         dtype_parts = dtype_info.split(':')\n",
    "         dtype = dtype_parts[0]\n",
    "         min_length = int(dtype_parts[1]) if len(dtype_parts) > 1 else None\n",
    "         max_length = int(dtype_parts[2]) if len(dtype_parts) > 2 else None\n",
    "         if dtype == 'int':\n",
    "             if min_length and max_length:\n",
    "                 data[col] = [random_integer(min_length, max_length) for _ in range(num_rows)]\n",
    "             else:\n",
    "                 data[col] = np.random.randint(1, 100, num_rows)\n",
    "         elif dtype == 'float':\n",
    "             data[col] = np.random.rand(num_rows) * 100\n",
    "         elif dtype == 'name':\n",
    "             data[col] = [faker.name() for _ in range(num_rows)]\n",
    "         elif dtype == 'date':\n",
    "             data[col] = [faker.date() for _ in range(num_rows)]\n",
    "         elif dtype == 'datetime':\n",
    "             data[col] = [faker.date_time().isoformat() for _ in range(num_rows)]\n",
    "         elif dtype == 'LOB':\n",
    "             data[col] = np.random.choice(['MORTGAGE'], num_rows)\n",
    "         elif dtype == 'str':\n",
    "             if min_length and max_length:\n",
    "                 lengths = np.random.randint(min_length, max_length + 1, num_rows)\n",
    "                 data[col] = [random_string(length) for length in lengths]\n",
    "             elif min_length:\n",
    "                 data[col] = [random_string(min_length) for _ in range(num_rows)]\n",
    "             else:\n",
    "                 data[col] = np.random.choice(['Madrid', 'Liverpool'], num_rows)\n",
    "         else:\n",
    "             data[col] = np.random.choice(['unknown'], num_rows)\n",
    "     return pd.DataFrame(data)\n",
    " # Load all transposed schema files\n",
    " schema_files = glob.glob('lookup_schema.csv')  # Adjust the pattern if needed\n",
    " # Generate and save test data for each schema file\n",
    " num_rows = 10\n",
    " for schema_file in schema_files:\n",
    "     transposed_schema = pd.read_csv(schema_file, header=None)\n",
    "     test_data = generate_data(transposed_schema, num_rows)\n",
    "     output_csv_file = 'lookup.csv'\n",
    "     output_json_file = 'lookup.json'\n",
    "     test_data.to_csv(output_csv_file, index=False)\n",
    "     test_data.to_json(output_json_file,index=False)\n",
    "     print(f\"Test data generated and saved to '{output_csv_file}'\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON CONVERTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All CSV files have been converted to JSON and saved to 'all_csv_files_data.json'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "\n",
    "# Function to convert a single CSV file to JSON\n",
    "def convert_csv_to_json(file_path):\n",
    "    with open(file_path, 'r') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        data = [row for row in csv_reader]\n",
    "    return data\n",
    "\n",
    "# Directory containing the CSV files\n",
    "directory = 'output'  # Replace with the actual directory containing the CSV files\n",
    "\n",
    "# List to store JSON data for all files\n",
    "all_files_data = []\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):  # Process only .csv files\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        file_data = convert_csv_to_json(file_path)\n",
    "        all_files_data.append({\n",
    "            'filename': filename,\n",
    "            'content': file_data\n",
    "        })\n",
    "\n",
    "# Convert the list of all files data to JSON format\n",
    "json_data = json.dumps(all_files_data, indent=4)\n",
    "\n",
    "# Save the JSON data to a file\n",
    "with open('all_csv_files_data.json', 'w') as json_file:\n",
    "    json_file.write(json_data)\n",
    "\n",
    "print(\"All CSV files have been converted to JSON and saved to 'all_csv_files_data.json'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WITH LOOKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " import pandas as pd\n",
    " import numpy as np\n",
    " import glob\n",
    " import random\n",
    " import string\n",
    "\n",
    " from faker import Faker\n",
    "\n",
    " faker=Faker()\n",
    "\n",
    " # Function to generate random string of a given length\n",
    " def random_string(length):\n",
    "     return ''.join(random.choices(string.ascii_lowercase, k=length))\n",
    " # Function to generate random integer with a specific number of digits \n",
    " def random_integer(min_digits, max_digits):\n",
    "     min_value = 10**(min_digits - 1)\n",
    "     max_value = 10**max_digits - 1\n",
    "     return np.random.randint(min_value, max_value + 1,dtype=np.int64)\n",
    " # Function to generate data based on schema\n",
    " def generate_data(schema, num_rows, lookup_data=None):\n",
    "     data = {}\n",
    "     for index, row in schema.iterrows():\n",
    "         col = row[0]\n",
    "         dtype_info = row[1]\n",
    "         dtype_parts = dtype_info.split(':')\n",
    "         dtype = dtype_parts[0]\n",
    "         min_length = int(dtype_parts[1]) if len(dtype_parts) > 1 else None\n",
    "         max_length = int(dtype_parts[2]) if len(dtype_parts) > 2 else None\n",
    "         if lookup_data is not None and col in lookup_data.columns:\n",
    "             data[col] = np.random.choice(lookup_data[col].values, num_rows)\n",
    "         elif dtype == 'int':\n",
    "             if min_length and max_length:\n",
    "                 data[col] = [random_integer(min_length, max_length) for _ in range(num_rows)]\n",
    "             else:\n",
    "                 data[col] = np.random.randint(1, 100, num_rows)\n",
    "         elif dtype == 'float':\n",
    "             data[col] = np.random.rand(num_rows) * 100\n",
    "         elif dtype == 'name':\n",
    "             data[col] = [faker.name() for _ in range(num_rows)]\n",
    "         elif dtype == 'date':\n",
    "             data[col] = [faker.date() for _ in range(num_rows)]\n",
    "         elif dtype == 'datetime':\n",
    "             data[col] = [faker.date_time().isoformat() for _ in range(num_rows)]\n",
    "         elif dtype == 'bool':\n",
    "             data[col] = np.random.choice(['Y', 'N'], num_rows)\n",
    "         elif dtype == 'str':\n",
    "             if min_length and max_length:\n",
    "                 lengths = np.random.randint(min_length, max_length + 1, num_rows)\n",
    "                 data[col] = [random_string(length) for length in lengths]\n",
    "             elif min_length:\n",
    "                 data[col] = [random_string(min_length) for _ in range(num_rows)]\n",
    "             else:\n",
    "                 data[col] = np.random.choice(['AUTO', 'DEPOSITS', 'MORTGAGE'], num_rows)\n",
    "         else:\n",
    "             data[col] = np.random.choice(['unknown'], num_rows)\n",
    "     return pd.DataFrame(data)\n",
    " # Load all transposed schema files\n",
    " schema_files = glob.glob('schema_*.csv')  # Adjust the pattern if needed\n",
    " # Load the lookup file\n",
    " lookup_data = pd.read_csv('lookup.csv')  # Adjust the file name if needed\n",
    " # Generate and save test data for each schema file\n",
    " num_rows = 100\n",
    " for schema_file in schema_files:\n",
    "     transposed_schema = pd.read_csv(schema_file, header=None)\n",
    "     test_data = generate_data(transposed_schema, num_rows, lookup_data=lookup_data)\n",
    "     output_file = schema_file.replace('schema_', 'test_data_')  # Create corresponding output file name\n",
    "     test_data.to_csv(output_file, index=False)\n",
    "     print(f\"Test data generated and saved to '{output_file}'\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
